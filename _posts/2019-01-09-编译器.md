---
layout: post
title: 编译器原理摘要
---
编译器：源代码 -> Byte code/Assembly

1. 词法分析Lexical analysis
2. 解析 Parsing
3. 语义分析 Semantic
4. 优化 Optimization
5. 代码生成

以往的编译器语义分析部分少， 当前主流编译器着重于语义分析和代码优化。

## 1 词法分析
输入： 源代码

输出： token: <token class, string>， 例如<token class, lexeme>或<int, 6>

Token Classes: 
1. Identifier: 变量名称
2. Integer: 非空数字string
3. Keyword: else, if, while...
4. White spaces: 空格/tab
5. Operator: +, -, * , ...

### 1.1 Look Ahead
在Fortran， 空格不重要，导致要求look ahead， 例如
```
DO 5 I = 1,25 (1-25循环)
DO 5 I = 1.25 (~ DO5I = 1.25)
```
必须要看到","或者"."才能分析出DO是关键词还是变量名， **故在词法分析中要减少此类lookahead。**

### 1.2 Formal Language
包含字母表， meaning func(e.g. RE)。 例如在regular lang中， RE代表了所有此类Regular Language中可能包含的所有组合。 使用meaning func可以更好地区分语法和语义， 并且可将多种语法统一到同一语义， 例如下例中语法不同语义相同。 **注意不能出现一种语法有多个语义**。

```
0*

0 + 0*
```

### 1.3 Regular Language
使用RE将字符串分类到token class。

RE单位：
1. 空字符 \epsilon
2. 字符 'a', 'b', ...

RE操作：
1. union: A + B
2. concatenation: AB
3. iteration: A<sup>\*</sup>


### 1.4 Lexical Specificaiton

使用RE表达token class

__Keyword__: ['i''f' + 'e''l''s''e' + ...]

__Integer__: 
```
digit = '1' + '2' + '3' + ...
digits = digit+
```
__Identifier__: 
```
letter = [a-zA-Z]
```

__Whitespace__:
```
' ' + '\n' + '\+'
```

__ERROR__:
匹配所有不在以上token class中的输入

<img src="{{site.baseurl}}/images/pascall_re.png" title="Pascal中的token class语法">

形成Regular Language（R = Keyword + Identifier + Number + ...)。 将输入的所有substring与R匹配。

substring**由长到短**匹配到对应token class，后将此substring删除。 由长到短的匹配顺序避免了例如将关键词的开头匹配为变量的情况。 若字符串可匹配多个token class则**根据token class 优先级选择**。 

### 1.5 有限自动机实现 Lexical Specification(LS)

我们可以使用NFA或DFA加上一个二维数组查找实现LS。

<img src="{{site.baseurl}}/images/dfa_lex.png" title="Lexical Specification的DFA实现">

DFA和NFA区别： 
1. DFA无epsilon移动
2. DFA在当前状态下，同一输入的结果唯一（NFA可以走向多个状态）
3. DFA的状态可以是多个NFA状态的集合
4. 对同一输入，DFA路径唯一，NFA可选
5. NFA只需输入能停留在任意结束状态即accept
6. 一般情况下，DFA运行更快， NFA更小

RE转NFA例：

<img src="{{site.baseurl}}/images/re_nfa1.png" title="RE转NFA例1" width="400" height="200">
<img src="{{site.baseurl}}/images/re_nfa2.png" title="RE转NFA例2" width="400" height="200">

接下来，创建二维数组查找各个状态在不同输入字符下的下一状态。 例如， 

<img src="{{site.baseurl}}/images/lex_2dtable.png" title="二维数组实现DFA">

| 当前状态/输入    | 0             | 1     |
| -------------   |:-------------:| -----:|
| S               | T             | U     |
| T               | T             | U     |
| U               | T             | U     |

```
i = 0
state = 0

while input[i]:
	state = table2d[state, input[i]]
	i += 1
```

此时注意到二维数组的大小取决于语言字符和状态的数量，并且每行有相当多的重复。 出于优化考虑可以使用一维数组指向一维数组的方式压缩表格， 但是相应地会降低查找速度。


## 2 解析
输入： token **stream**: <token class, string>， 例如<token class, lexeme>或<int, 6>

输出： 抽象语法树 Abstract Syntax Tree

解析的目的是对语法进行匹配并弥补RE不能进行数量匹配的缺点， 例如(((())))或者嵌套的if/else （因为状态数量有限）。

### Contex Free Grammar (CFG)
上下文无关语法包含几个要素：Terminal(T), Non-terminal(N), Start symbol(S), Productions(P)。 T为不可再次分割的token比如<Int, 1>, N为可进一步分割的tokens比如'a = 1 + 2', S为非T输入， productions为分割规则。 而通过分割规则，我们可以推导出对应的解析树（非抽象语法树）

productions例：
N -> N + N | N * N | (N) | identifier



## 4 优化
X = Y * 0 与 X = 0 不等价， 因为在IEEE standard中 NAN * 0 = NAN

